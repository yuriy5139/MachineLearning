{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5bafdb5-1d92-4d79-856e-5f5a3137013e",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "### THis notebook is based on several study programs including Stanford cs231n, Jeremy Howard Fast AI, MIT Deep Learning book, website https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/ and some others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdde017-0526-4990-be3b-9276de5b8ccc",
   "metadata": {},
   "source": [
    "### 1. Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bab975-167e-4f86-9834-2a1e3f4908f8",
   "metadata": {},
   "source": [
    "Assume we are trying to measure a distance to some moving object with a help of a laser meter. At every moment in time t we obtain a measurement x(t) from out meter. Let's suppose that this meter is subject to noize, so our natural intention will be to take some average over measurements to better locate the object. Obviously, more recent measurements must provide more significant input to the average than more old ones, so the average shall be weighted. This can be achieved with a help of a weighting function w(a) which returns weight depending on a - time of a measurement. If we do this measurements continuously we can obtain the function S(t) which represents a smoothed estimate of object's location:\n",
    "#### $$S(t) = \\int x(a)w(t-a)da$$\n",
    "This operation is called convolution and is denoted with the asterisk sign. In our example w(a) must be a PDF, otherwise we will not receive a weighted average. Also w(a) shall be 0 for all negative values, as we can not predict the future. But in general case this conditions are not mandatory, so w(a) can be any smooth function allowing the integral to be valid. \n",
    "Returning to our example, the case with continuous measurements is a little unrealistic. More practically we will rather receive discrete measurements at moments t and our convolution will become discrete:\n",
    "#### $$ S(t) = \\sum_{a=-\\infty}^{+\\infty} x(t)w(t-a)$$\n",
    "Traditionally, x(t) is called the input, and w(a) is called the kernel or the filter. In multidimensional kase, e.g. for a two-dimensional image I the convolution using kernel K will give us the following expression:\n",
    "#### $$S(i,j) = (I*K)(i,j) = \\sum_m\\sum_nI(i, j)K(i-m, j-n)$$\n",
    "Convolution operation is commutative, so we can equivalently write\n",
    "#### $$S(i,j) = (I*K)(i,j) = \\sum_m\\sum_nI(i-m, j-n)K(m, n)$$\n",
    "If we write the same equation with plus signes instead of minus signes in index of I, we will get the cross-correlation operation. Changing the signes in the operation is de-facto changing the kernel by rotating it by 180 degrees:\n",
    "#### $$S(i,j) = (I*K)(i,j) = \\sum_m\\sum_nI(i+m, j+n)K(m, n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a882e-343f-4453-81ec-6a516a98e615",
   "metadata": {},
   "source": [
    "In machine learning convolution operation is used in convolutional layers which substitute linear layers due to higher effectiveness. In fact, convolution operation is similar to matrix multiplication in linear layer, except that the same weights of a kernel are shared between input-output pairs and not a single weight for each pair is used. This causes sparse interactions (not every output depends on every input) and decrease in the number of weights we would need to compute if all layers were linear. \n",
    "Let's implement convolution layer and test in in our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2163cb-a61d-495f-b7b1-796cef8349f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b04b75c-a3de-49a3-b1bf-e1ea3e45e418",
   "metadata": {},
   "source": [
    "First of all, we would like to have a function that pads an input image with zeros. If we check the convolution function, calculating output i, j will require us to step m pixels up and n pixels left at point i, j = 0, 0. Without padding we will have to start with pixel m, n in the input image, otherwise, there is no other source of data for negative m and n indexes multiplication. Having padded the input image instead we can have output shape the same as input shape which is convenient.\n",
    "\n",
    "As this notebook was creaed with educational intentions mainly, we will work with 1-channel images only, which is enough to show how convolution layer is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963eb5bb-50fc-4cb7-b860-c531dc11f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_with_zeros(X):\n",
    "    \"\"\"pads input image with one pixel of zeros at every edge\n",
    "    \n",
    "    \n",
    "    Supports 2-d input (one-channel images) and 3-d input (batches of one-channel images)\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(X.shape) == 2:\n",
    "        X_pad = np.zeros((X.shape[0] + 2, X.shape[1] + 2))\n",
    "        X_pad[1:-1,1:-1] = X\n",
    "        return X_pad\n",
    "    elif len(X.shape) == 3:\n",
    "        result = []\n",
    "        for img in X:\n",
    "            img_pad = np.zeros((img.shape[0] + 2, img.shape[1] + 2))\n",
    "            img_pad[1:-1,1:-1] = img\n",
    "            result.append(img_pad)\n",
    "        return np.array(result)\n",
    "    else:\n",
    "        print(\"Only (H x W) and (Batch x H x W) shapes are supported\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c29d1c-7961-4401-b395-e8cc10b2e18f",
   "metadata": {},
   "source": [
    "Let's test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11250ff1-686d-444c-89ee-ea11436c6c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pict = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc003486-8544-4732-8cc9-f3def87b1a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 1., 2., 3., 0.],\n",
       "       [0., 4., 5., 6., 0.],\n",
       "       [0., 7., 8., 9., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_with_zeros(pict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac73a0ee-dd31-46f3-8f2a-909b27611101",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = []\n",
    "for i in range(8):\n",
    "    batch.append(pict)\n",
    "batch_padded = pad_with_zeros(np.array(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7984a7a-2993-4d04-b88d-84618882df27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 5, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "007540a6-87d6-4ec4-a44e-68b2f347ffbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 1., 2., 3., 0.],\n",
       "       [0., 4., 5., 6., 0.],\n",
       "       [0., 7., 8., 9., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e34026b-906d-4d7c-b5cb-c70338334ea2",
   "metadata": {},
   "source": [
    "Looks well. Let's implement 2d convolution operation - we will need it while constructing convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f13b2d8-7c10-422d-8b09-03443e575eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(X, K, pad = False):\n",
    "    \n",
    "    \n",
    "    \"\"\"Convolutional operation on 2-d input X and 2-d kernel K\"\"\"\n",
    "    \n",
    "    \n",
    "    if pad:\n",
    "        X = pad_with_zeros(X)\n",
    "        \n",
    "    h, w = X.shape[0], X.shape[1]\n",
    "    k1, k2 = K.shape[0], K.shape[1]\n",
    "    result = np.zeros((h - k1 + 1, w - k2 + 1))\n",
    "    \n",
    "    for i in range(0 + k1 - 1, result.shape[0] + k1 - 1):\n",
    "        for j in range(0 + k2 - 1, result.shape[1] + k2 - 1):\n",
    "            result[i - k1 + 1, j - k2 + 1] = (X[i - k1 + 1: i + 1, j - k2 + 1: j + 1] * K).sum()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaa2cc6-fd86-4883-ae8f-4d1d1f158e42",
   "metadata": {},
   "source": [
    "Let's test it either:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e80aa315-5bac-4809-8310-57528570ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebc20f64-08fd-41e2-9533-af66e047ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.array([[0.0, 1.0], [2.0, 3.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02100fa8-ebd2-4cba-b31a-9044bf965e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25., 31.],\n",
       "       [43., 49.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b236d88d-33b1-4f33-97a8-a7bd64a6a383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  8., 13.,  6.],\n",
       "       [13., 25., 31., 12.],\n",
       "       [25., 43., 49., 18.],\n",
       "       [ 7.,  8.,  9.,  0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(X, K, pad = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5866c76d-c28a-4ecd-a101-f85e56fd6191",
   "metadata": {},
   "source": [
    "It works. Let's implement now convolution layer. In forward pass it just performs conv2d operation for every image in the batch. In backward pass two types of gradients are traditionally calculated: gradients of the loss function with respect to the weights of the kernel to perform a gradient step and gratients of the loss function with respect to the inputs to propagate error down the network. For gradient calculation we will need a function that rotates matrixes by 180 degrees, so let't implement it first. We omit the deriviation of both gradients here and just use the well-known formulas:\n",
    "#### $$\\frac{\\partial E}{\\partial w_{m,n}} = \\sum_{i=0}^{H-k1}\\sum_{j=0}^{W-k2}x_{m+i, n+j}\\delta_{ij} = rot_{180}(\\Delta)*X $$\n",
    "#### $$\\frac{\\partial E}{\\partial x_{i,j}} = \\sum_{m=0}^{k1-1}\\sum_{n=0}^{k2-1}\\delta_{i-m, j-n}rot_{180}(w_{m,n}) = rot_{180}(W)*\\Delta $$\n",
    "where $\\delta_{i, j}$ are components of upstream gradients matrix $\\Delta$ incoming to our convolutional layer,\n",
    "\n",
    "$w_{m,n}$ are components of weight matrix $W$ of the kernel, \n",
    "\n",
    "$x_{i,j}$ are components of convolutional layer's input matrix $X$,\n",
    "\n",
    "$H, W$ - input's height and width,\n",
    "\n",
    "$k1, k2$ - kernel's height and width. Unlike many online resources we consider nonlinearity activation to be OUT of Conv Layer, hence these simple formulas.\n",
    "\n",
    "It is also important to note that the rotation of gradient matrix in the first formula is required to change cross-correlation operation into convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaf333ec-86ab-469b-a0db-aa1c956929a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot180(X):\n",
    "    return np.rot90(np.rot90(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf39658b-e9e3-45cb-a9bb-6bb3c3db374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer:\n",
    "    \"\"\" Convolution layer\n",
    "    \n",
    "    \n",
    "    Makes convolution operation with 2- or 3-dimensional input and 2-dimensional kernel.\n",
    "    \n",
    "    Init Parameters:\n",
    "    kernel_size - height (width) of the kernel. Only square kerlnels are supported.\n",
    "    pad - whether to pad an input image with zeros\n",
    "    \n",
    "    forward() parameters:\n",
    "    X - input vector of size height x width or batch_size x height x width. Only one-channel images are supported.\n",
    "    \n",
    "    backward() parameters:\n",
    "    upstr_grad -- upstream (incoming) gradients from the layer closer to the end of the network\n",
    "    lr -- learning rate\n",
    "    debug -- debug level. debug == 2 shows gradients on every learning step.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, kernel_size = 3, pad = False):\n",
    "        # pytorch-stryle weights initialization\n",
    "        n = kernel_size**2\n",
    "        self.kernel = np.random.normal(0, math.sqrt(2. / n), (kernel_size, kernel_size)).astype(np.float32)\n",
    "        self.pad = pad\n",
    "        self.X_ = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        if len(X.shape) == 2:\n",
    "            if self.pad: \n",
    "                X = pad_with_zeros(X)\n",
    "            self.X_ = X\n",
    "            return conv2d(X, self.kernel)\n",
    "        \n",
    "        elif len(X.shape) == 3:\n",
    "            if self.pad: \n",
    "                X = pad_with_zeros(X)\n",
    "            self.X_ = X\n",
    "            result = []\n",
    "            for img in X:\n",
    "                result.append(conv2d(img, self.kernel))\n",
    "            return np.array(result)\n",
    "                    \n",
    "        else:\n",
    "            print(\"Only (H x W) and (Batch x H x W) shapes are supported\")\n",
    "            return None\n",
    "    \n",
    "    def backward(self, upstr_grad, lr = 0.01, debug = 0):\n",
    "        if len(upstr_grad.shape) == 2:\n",
    "            # calculate grads w.r.t. weights\n",
    "            grad_w = conv2d(self.X_, rot180(upstr_grad))\n",
    "            if debug == 1: print(f'Conv: grad_w.shape = {grad_w.shape}, upstr_grad.shape = {upstr_grad.shape}')\n",
    "            if debug > 1: print(f'Conv: grad_w = {grad_w}')\n",
    "\n",
    "            # calculate grads w.r.t. input\n",
    "            for i in range(self.X_.shape[0] - self.kernel.shape[0] - self.pad):\n",
    "                upstr_grad = pad_with_zeros(upstr_grad)\n",
    "            grad_x = conv2d(upstr_grad, rot180(self.kernel))\n",
    "            if debug == 1: print(f'Conv: grad_x.shape = {grad_x.shape}, upstr_grad.shape = {upstr_grad.shape}')\n",
    "            if debug > 1: print(f'Conv: grad_x = {grad_x}')\n",
    "\n",
    "            self.kernel += -1 * grad_w * lr # домножаем на -1, так как градиентный шаг выполняется в направлении антиградиента\n",
    "            return grad_x\n",
    "        \n",
    "        elif len(upstr_grad.shape) == 3:\n",
    "            # calculate grads w.r.t. weights\n",
    "            grad_w_batch = []\n",
    "            for i in range(upstr_grad.shape[0]):\n",
    "                grad_w = conv2d(self.X_[i], rot180(upstr_grad[i]))\n",
    "                grad_w_batch.append(grad_w)\n",
    "            grad_w_batch = np.array(grad_w_batch)\n",
    "            \n",
    "            if debug == 1: print(f'Conv: grad_w_batch.shape = {grad_w_batch.shape}, upstr_grad.shape = {upstr_grad.shape}')\n",
    "            if debug > 1: print(f'Conv: grad_w_batch = {grad_w_batch}')\n",
    "            \n",
    "             # calculate grads w.r.t. input\n",
    "            grad_x_batch = []\n",
    "            for i in range(upstr_grad.shape[0]):\n",
    "                ug = upstr_grad[i]\n",
    "                for j in range(2 - self.pad):    \n",
    "                    ug = pad_with_zeros(ug)\n",
    "                grad_x = conv2d(ug, rot180(self.kernel))\n",
    "                grad_x_batch.append(grad_x)\n",
    "            grad_x_batch = np.array(grad_x_batch)\n",
    "            if debug == 1: print(f'Conv: grad_x_batch.shape = {grad_x_batch.shape}, upstr_grad.shape = {upstr_grad.shape}')\n",
    "            if debug > 1: print(f'Conv: grad_x_batch = {grad_x_batch}')\n",
    "            return grad_x_batch\n",
    "            \n",
    "            self.kernel += -1 * grad_w_batch.mean(axis = 0) * lr # multiply by -1 as we need to go in the opposite to gradient direction\n",
    "        \n",
    "        else:\n",
    "            print(\"Only (H x W) and (Batch x H x W) shapes are supported\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e2015-5661-4cf7-b768-4d2d1cfb2657",
   "metadata": {},
   "source": [
    "Let's make some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "393c852b-c451-438b-ab60-91357d3fd745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.61428181, -4.71658109],\n",
       "       [-4.92117965, -5.02347893]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CL = ConvLayer(kernel_size = 2)\n",
    "CL.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87462c5b-08d9-44ac-b213-b9d4b3dd91cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv: grad_w.shape = (2, 2), upstr_grad.shape = (2, 2)\n",
      "Conv: grad_x.shape = (3, 3), upstr_grad.shape = (4, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.04236015,  1.46982443],\n",
       "       [ 0.0847203 ,  2.50588053,  0.33146906],\n",
       "       [-0.95225698, -2.75283924, -1.13835537]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upstr_grad = np.array([[0, 1], [2, 1]])\n",
    "CL.backward(upstr_grad, debug = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36730d42-0e99-45f5-8132-046b250a4016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch = []\n",
    "for i in range(5):\n",
    "    X_batch.append(X)\n",
    "X_batch = np.array(X_batch)\n",
    "X_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9167607-a877-4a5d-866c-0ae3027ab4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -7.05428183,  -7.83658112],\n",
       "        [ -9.40117969, -10.18347897]],\n",
       "\n",
       "       [[ -7.05428183,  -7.83658112],\n",
       "        [ -9.40117969, -10.18347897]],\n",
       "\n",
       "       [[ -7.05428183,  -7.83658112],\n",
       "        [ -9.40117969, -10.18347897]],\n",
       "\n",
       "       [[ -7.05428183,  -7.83658112],\n",
       "        [ -9.40117969, -10.18347897]],\n",
       "\n",
       "       [[ -7.05428183,  -7.83658112],\n",
       "        [ -9.40117969, -10.18347897]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fwres = CL.forward(X_batch)\n",
    "fwres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3bd713b-64c4-43f4-b3c6-50a4d4ab1854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv: grad_w_batch.shape = (5, 2, 2), upstr_grad.shape = (5, 2, 2)\n",
      "Conv: grad_x_batch.shape = (5, 5, 5), upstr_grad.shape = (5, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "upstr_grad = np.array([[[1, 1], [1, 1]], [[1, 1], [1, 1]], [[1, 1], [1, 1]], [[1, 1], [1, 1]], [[1, 1], [1, 1]]])\n",
    "downstr_grad = CL.backward(upstr_grad, debug = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131891c3-d485-47f3-b47f-781000f84945",
   "metadata": {},
   "source": [
    "Let's try with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0ef635f-f845-43a4-821e-bea096e7323e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.32142159,   1.39750081,   2.1635949 ],\n",
       "       [ -3.11347791,   1.94523534,   7.46344732],\n",
       "       [-11.79537266,  -5.67012757,   9.92485227]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CL = ConvLayer(kernel_size = 3, pad = True)\n",
    "CL.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75c363c7-6885-4ae5-ac21-587c81b14a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv: grad_w.shape = (3, 3), upstr_grad.shape = (3, 3)\n",
      "Conv: grad_x.shape = (3, 3), upstr_grad.shape = (5, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.88661829,  2.56531267, -0.87144601],\n",
       "       [ 3.60151109,  2.91105985, -5.22790636],\n",
       "       [ 2.8956083 , -2.11931109, -1.891187  ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upstr_grad = np.array([[0, 1, 2], [1, 2, 3], [2, 3, 0]])\n",
    "CL.backward(upstr_grad, debug = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23d3fb99-6c06-4721-9b87-0793cd0105a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CL.forward(X_batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "624c8ae8-e56a-4df7-9dcd-80c283471430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv: grad_w_batch.shape = (5, 3, 3), upstr_grad.shape = (5, 3, 3)\n",
      "Conv: grad_x_batch.shape = (5, 3, 3), upstr_grad.shape = (5, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "upstr_grad = np.array([[[1, 1, 1], [1, 1, 1], [1, 1, 1]],\n",
    "                       [[1, 1, 1], [1, 1, 1], [1, 1, 1]],\n",
    "                       [[1, 1, 1], [1, 1, 1], [1, 1, 1]],\n",
    "                       [[1, 1, 1], [1, 1, 1], [1, 1, 1]],\n",
    "                       [[1, 1, 1], [1, 1, 1], [1, 1, 1]]])\n",
    "\n",
    "downstr_grad = CL.backward(upstr_grad, debug = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a0640ee-4d37-4da0-9658-d837f7d878ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downstr_grad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ccd3c1-51d5-4aee-be60-f9d3a4b23ce5",
   "metadata": {},
   "source": [
    "Looks well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265d68c-cae1-483e-b153-c2b51870358a",
   "metadata": {},
   "source": [
    "### 2. Hand-written digits recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4358c7-1686-43b2-892d-4596f0d0cbc5",
   "metadata": {},
   "source": [
    "Let's build a simple convolutional neural network to recognize hand-written digits. We will reuse some classes from our previous notebook https://github.com/yuriy5139/MachineLearning/blob/master/Neural%20Networks%20basics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f796f7cf-92c8-4d0c-a8fa-8d32951a3f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    \"\"\"Fully Connected Layer. \n",
    "    \n",
    "    \n",
    "    Initializer's parameters:\n",
    "    inp -- the number of input neurons\n",
    "    out -- the number of output neurons\n",
    "    \n",
    "    The weights are initialized as in PyTorch.\n",
    "    \n",
    "    forward() parameters:\n",
    "    X -- matix of shape (N, inp), where N is the size of a batch\n",
    "    \n",
    "    backward() parameters:\n",
    "    upstr_grad -- upstream (incoming) gradients from the layer closer to the end of the network\n",
    "    lr -- learning rate\n",
    "    debug -- debug level. debug == 2 shows gradients on every learning step.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, inp, out):\n",
    "        self.inp = inp\n",
    "        self.out = out\n",
    "        stdv = 1.0 / np.sqrt(inp)\n",
    "        self.W = np.random.default_rng().uniform(-stdv, stdv, (inp, out)).astype(np.float32)\n",
    "        self.X_ = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X_ = X.astype(np.float32)\n",
    "        return np.dot(X.astype(np.float32), self.W)\n",
    "    \n",
    "    def backward(self, upstr_grad, lr = 0.01, debug = 0): \n",
    "        # gradients are averaged by batch size, since if we not do it, the deltas will grow proportionally to batch size\n",
    "        delta_W = np.dot(np.transpose(self.X_), upstr_grad.astype(np.float32)) / self.X_.shape[0]\n",
    "        \n",
    "        self.W += (-1) * lr * delta_W # multiply by -1 to move in the opposite of gradient direction\n",
    "        if debug == 2: print(f'Linear Layer: W gradients = {delta_W}')\n",
    "        if debug == 2: print(f'Linear Layer: new weights = {self.W}')\n",
    "        return np.dot(upstr_grad.astype(np.float32), np.transpose(self.W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af1b2d4b-04d1-4bf2-9e51-7f23d93dda12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    \"\"\"Rectified Linear Unit\n",
    "    \n",
    "    lr and debug parameters are stubs allowing us to call backward() function with the same set of parameters for every layer.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.X_ = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.X_ = X\n",
    "        return np.where(X <= 0, 0, X)\n",
    "    \n",
    "    def backward(self, upstr_grad, lr = None, debug = 0):\n",
    "        if debug: print(f'Relu: upstr_grad.shape = {upstr_grad.shape}, self.X_.shape = {self.X_.shape}')\n",
    "        if debug > 1: print(f'Relu: upstr_grad = {upstr_grad}, self.X_ = {self.X_}')\n",
    "        return upstr_grad * np.where(self.X_ <= 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e1a5888-75a4-4932-a4d7-2a54d1b308c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeakyRelu:\n",
    "    \n",
    "    \"\"\"Non-linearity equivalent to Relu, but having non-zero behaviour in negative zone with alpha coefficient\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha):\n",
    "        self.X_ = None\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.X_ = X\n",
    "        return np.where(X <= 0, X * self.alpha, X)\n",
    "    \n",
    "    def backward(self, upstr_grad, lr = None, debug = 0):\n",
    "        return upstr_grad * np.where(self.X_ <= 0, self.alpha, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42ce59ec-675c-4936-ab4e-e74d7f3450d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    \n",
    "    \"\"\"Tanh non-linearity\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.out = np.tanh(X)\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self, upstream_grad, lr = None, debug = 0):\n",
    "        return upstream_grad * (1 - self.out ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b0a6522-a0d2-4123-9cb3-508d217b14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CELoss(Y_true, Y_hat):\n",
    "    \"\"\" Cross-Entropy loss function\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    Y_true -- true labels of a training set. Matrix of shape (N, T), where N is the batch size, T is the number of classes. \n",
    "        0 everywhere except for the correct class where it is 1\n",
    "    Y_hat -- model's predictions. Matrix of shape (N, T), where N is the batch size, T is the number of classes. \n",
    "        Contains probabilities of classes in range [0, 1]\n",
    "    \n",
    "    Returns a tuple of scalar loss value and a matrix of gradients of shape (N, T)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    eps = 1e-10\n",
    "    Y_loss = -np.log2(Y_hat + eps)\n",
    "    Y_grad = -1 / (np.log(2) * Y_hat + eps)\n",
    "    loss = Y_loss * Y_true\n",
    "    grad = Y_grad * Y_true\n",
    "    return loss.sum(), grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e05e7049-4a8a-4168-9404-38e43ff94ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sm_jacobian(sm_out):\n",
    "    \"\"\" Calculates Jacobian matrix for SoftMax\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    sm_out -- an output of a SoftMax layer, cached during a forward pass. A matrix of shape (number of classes, 1)\n",
    "    If SoftMax input was a batch of shape (N x number of classes), every row of this matrix shall be a separate input for this function\n",
    "    \n",
    "    Returns a Jacobian of shape (number of classes x number of classes)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    jac = np.zeros((sm_out.shape[0], sm_out.shape[0]))\n",
    "    for i in range(sm_out.shape[0]):\n",
    "        for j in range(sm_out.shape[0]):\n",
    "            if i == j:\n",
    "                jac[i, j] = sm_out[i] * (1 - sm_out[i])\n",
    "            else:\n",
    "                jac[i, j] = -1 * sm_out[i] * sm_out[j]\n",
    "    return jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b490b46-f291-4658-bec1-c6ecab563bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    \"\"\" SoftMax layer\n",
    "    \n",
    "    \n",
    "    Supports only batches of size >= 2\n",
    "    \n",
    "    Using cached during forward pass values of output, on backward pass forms Jacobians of partial derivatives with a help of create_sm_jacobian(). \n",
    "    Since N such Jacobians form a matrix of shape (N x number of classes x number of classes), dot product of such a matrix by incoming gradients \n",
    "    is only possible pairwise: one row of incoming gradient shall be multiplied by a single Jacobian.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        exps = np.exp(X)\n",
    "        sum_col = np.reshape(np.sum(exps, axis = 1), (-1, 1))\n",
    "        sums = sum_col\n",
    "        for i in range(X.shape[1] - 1):\n",
    "            sums = np.concatenate((sums, sum_col), axis = 1)\n",
    "        self.out = exps / sums\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self, upstream_grad, lr = None, debug = 0):\n",
    "        gradients = np.array([])\n",
    "        for ug, sm_out in zip(upstream_grad, self.out):\n",
    "            SMJ = create_sm_jacobian(sm_out)\n",
    "            grad = np.dot(ug, SMJ)\n",
    "            gradients = np.append(gradients, grad)\n",
    "        return np.reshape(gradients, (upstream_grad.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43debfcf-6d27-4428-a6f0-4a426884a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network_multiclass:\n",
    "    \n",
    "    \"\"\"Same as Network class except for CELoss support\n",
    "    \n",
    "    inference_mode() and train_mode() methods were introduces to support BatchNorm layer switch of regimes. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def backward(self, upstr_grad, lr = 0.01, debug = 0):\n",
    "        for layer in reversed(self.layers):\n",
    "            upstr_grad = layer.backward(upstr_grad, lr = lr, debug = debug)\n",
    "        return upstr_grad\n",
    "    \n",
    "    def predict(self, X):\n",
    "        Y_hat = self.forward(X).argmax(axis = 1)\n",
    "        return Y_hat\n",
    "    \n",
    "    def inference_mode(self):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, BatchNorm):\n",
    "                layer.inference = True\n",
    "    \n",
    "    def train_mode(self):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, BatchNorm):\n",
    "                layer.inference = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c9f27de-9eae-4991-bd0e-7c1aef9e567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_enc(vec, num_classes):\n",
    "    \n",
    "    \"\"\"Converts a vector of scalar number of classes into a matrix of one-hot-encoded vectors\"\"\"\n",
    "    \n",
    "    assert len(vec.shape) == 2 and vec.shape[1] == 1, 'only [N x 1] vectors are supported'\n",
    "    \n",
    "    result = np.zeros((vec.shape[0], num_classes))\n",
    "    np.put_along_axis(result, vec, 1, axis = 1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "412151bb-3b10-4968-89f8-b319f16ed21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network_conv(Net, X_train, Y_train, batch_size = 8, lr = 1, criterion = 0.001, max_iter = 50, debug = 0):\n",
    "    \n",
    "    \"\"\"Same as train_network() but takes into account SoftMax as the last layer and uses CELoss\"\"\"\n",
    "    \n",
    "    batch_loss = 1e3\n",
    "    iteration = 0\n",
    "    Y_train_enc = one_hot_enc(np.reshape(Y_train, (-1, 1)), 10)\n",
    "    average_loss = 1e3\n",
    "    lmbd = 0.1\n",
    "    \n",
    "    while average_loss > criterion and iteration < max_iter:\n",
    "        \n",
    "        batch_index = random.sample([i for i in range(len(X_train))], batch_size)\n",
    "        Y_hat = Net.forward(X_train[batch_index])\n",
    "        batch_loss, grad = CELoss(Y_train_enc[batch_index], Y_hat)\n",
    "        \n",
    "        if iteration == 0:\n",
    "            average_loss = batch_loss\n",
    "        else:\n",
    "            average_loss = batch_loss * lmbd + (1 - lmbd) * average_loss\n",
    "        \n",
    "        period = math.ceil(max_iter / 30)\n",
    "        if iteration % period == 0: print(f'iteration {iteration}, average_loss = {average_loss}')\n",
    "        Net.backward(grad, lr = lr, debug = debug)\n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049321b-8884-494c-8627-a76c16b5b098",
   "metadata": {},
   "source": [
    "We will need a new flatten layer to be added between convolution layer and linear layer as linear layer supports only batches of vectors and does not support batches of matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f12a2502-71e6-4281-b943-2af1f8922867",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten():\n",
    "    \"\"\"Flatten layer \n",
    "    \n",
    "    \n",
    "    Reshapes matrix values on forward pass into a single vector appropriate to be an inpuf for a Fully-Connected Layer.\n",
    "    On backward pass implements the reverse operation. Supports matrixes of shape (Height x Width) and (Batch_size x Height x Width)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_dims = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.input_dims = X.shape\n",
    "        if len(X.shape) == 2:\n",
    "            return X.flatten()\n",
    "        elif len(X.shape) == 3:\n",
    "            result = []\n",
    "            for arr in X:\n",
    "                result.append(arr.flatten())\n",
    "            return np.array(result)\n",
    "        else:\n",
    "            print(\"Only (H x W) and (Batch x H x W) shapes are supported\")\n",
    "            return None\n",
    "            \n",
    "    \n",
    "    def backward(self, upstr_grad, lr = None, debug = 0):\n",
    "        return np.reshape(upstr_grad, self.input_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92a0c7e-0023-4dbd-9f76-4b2bd068c794",
   "metadata": {},
   "source": [
    "Let's import hand-written digits dataset. It contains 1797 grayscale images of 64 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df332950-386c-443f-bbcb-3aef321f7924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60730616-5c92-4bd2-b974-49e14632491d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e275539d-80e9-468e-8be4-48e8571332a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca145daf-26ae-4816-8871-5d79051201fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7906186-cad6-4022-a02d-891021f8de0d",
   "metadata": {},
   "source": [
    "Let's check how these digits look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bde94855-23bb-4e32-ac7b-e8bc830bd10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90414c90-9b94-470e-b180-49ab0fd2e8cd",
   "metadata": {},
   "source": [
    "Neural networks perform better on normalized input. So, let's calculate a mean value and a standard deviation to perform normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4329db7c-2629-4c3e-879f-1679e7a8a642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = digits.data, digits.target\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1b08cd0-3137-4fa4-ac3c-f54cd3851684",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(X, (1797, 8, 8))\n",
    "MV = X.mean(axis=0)\n",
    "Stdev = np.sqrt(np.power(X - MV, 2).mean(axis=0) + 1e-10)\n",
    "X = (X - MV) / Stdev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49088fc-e947-46ce-947e-d67232e4c5c1",
   "metadata": {},
   "source": [
    "Creating train/test split and forming a simple network with three conv layers and LeakyRelu as an activation function. \n",
    "\n",
    "In this notebook we are not focused on finding the best model, so we don't do train/validation split and just run 2000 batches of 8 images each and check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d99f09f-bff9-4de2-9c3a-917eaa210086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=100, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66539b6c-1686-4133-918a-53af0760c7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, average_loss = 26.763306617736816\n",
      "iteration 67, average_loss = 19.835076151887385\n",
      "iteration 134, average_loss = 13.182710380641378\n",
      "iteration 201, average_loss = 10.369829744034773\n",
      "iteration 268, average_loss = 9.12194663431631\n",
      "iteration 335, average_loss = 7.423021041195967\n",
      "iteration 402, average_loss = 6.366991634197323\n",
      "iteration 469, average_loss = 4.966766400112278\n",
      "iteration 536, average_loss = 5.894840498353865\n",
      "iteration 603, average_loss = 6.830703365782879\n",
      "iteration 670, average_loss = 3.9237614766926283\n",
      "iteration 737, average_loss = 3.902878870824301\n",
      "iteration 804, average_loss = 5.220067508033055\n",
      "iteration 871, average_loss = 4.029189876779572\n",
      "iteration 938, average_loss = 6.151420125749912\n",
      "iteration 1005, average_loss = 4.041587711269675\n",
      "iteration 1072, average_loss = 3.406731936777214\n",
      "iteration 1139, average_loss = 5.2933398413088115\n",
      "iteration 1206, average_loss = 3.0118196688729872\n",
      "iteration 1273, average_loss = 4.750115020320189\n",
      "iteration 1340, average_loss = 3.5734240482417228\n",
      "iteration 1407, average_loss = 3.293110243401045\n",
      "iteration 1474, average_loss = 3.1542410437742667\n",
      "iteration 1541, average_loss = 3.2865095520995258\n",
      "iteration 1608, average_loss = 3.1917427628115864\n",
      "iteration 1675, average_loss = 2.75438357093211\n",
      "iteration 1742, average_loss = 2.800201532205776\n",
      "iteration 1809, average_loss = 3.126987493245274\n",
      "iteration 1876, average_loss = 2.7344360402865706\n",
      "iteration 1943, average_loss = 3.023028494976346\n"
     ]
    }
   ],
   "source": [
    "NNConv = Network_multiclass([ConvLayer(pad = True), LeakyRelu(alpha=0.2), \n",
    "                             ConvLayer(pad = True), LeakyRelu(alpha=0.2), \n",
    "                             ConvLayer(pad = True), LeakyRelu(alpha=0.2), \n",
    "                             Flatten(), Linear(64, 30), LeakyRelu(alpha=0.2), Linear(30, 10), Softmax()])\n",
    "train_network_conv(NNConv, train_X, train_Y, lr = 0.03, criterion = 0.1, max_iter = 2000, debug = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d3ae5-6edb-40e9-b3d0-37165147447e",
   "metadata": {},
   "source": [
    "Let's check if the model gives us any positive result. The classes are imbalanced so we will take macro-averages for precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "252c05c0-9345-461c-a375-e90559398022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.87, 0.9247222222222222, 0.8650507825507827)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "Y_hat = NNConv.forward(test_X)\n",
    "Y_hat = np.argmax(Y_hat, axis = 1)\n",
    "accuracy_score(test_Y, Y_hat), precision_score(test_Y, Y_hat, average = \"macro\"), recall_score(test_Y, Y_hat, average = \"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bef8226c-99d8-498f-80cb-728ab6a74a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf = confusion_matrix(test_Y, Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cdd6a2f4-31fe-4152-901f-e2b5eded3fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from string import ascii_uppercase\n",
    "from pandas import DataFrame\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "lines = [\"true \"+str(i) for i in range(10)]\n",
    "columns = [\"pred \"+str(i) for i in range(10)]\n",
    "conf_df = DataFrame(conf, index=lines, columns=columns)\n",
    "plt.figure(figsize = (12,8))\n",
    "ax = sn.heatmap(conf_df, cmap='Oranges', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627c0cd5-04c7-47a1-8262-cade3d999002",
   "metadata": {},
   "source": [
    "The results are not bad. Macro precision 0.92 is quite well for such a simple network. Confusion matrix gives us realistic results: 1 and 7 are mixed with 4 and they really look the same in hand-writing, 5 is mixed with 9, 9 is mixed with 3 and 4- same, they are very alike especially in such a low resolution.\n",
    "\n",
    "Let's give it a try and check what activations look like after the first and the second convolutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb4b8b0a-bfda-49b2-ae41-52195c060bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.matshow(digits.images[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "995a6265-d298-47fa-a3d5-8d6c4d6f81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_img = NNConv.layers[0].forward(digits.images[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac932e87-c98e-4cc4-980b-023274f71a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.matshow(conv_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bbd070fd-cce0-4261-b4a0-20f4d4664561",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_conv_img = NNConv.layers[2].forward(conv_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5efa3069-bff2-4d12-a5ae-bacc0200e15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAM7klEQVR4nO3db2xd9X3H8c8HJyZeTBIlsILiUEBCkaBiSYhQIiq0EVHBWtEnewBSi1ptZEJbBWxS1ezJ1Ec8qzoJVKmCdIgCVUsIILSxIpUIVdrIkhBaSNKpICoShTr/inGwFoy/e3BPIi849bFzfj+bfN8vycr19fX5/Gzn43Pu9bn364gQgAvbRXO9AADlUXQgAYoOJEDRgQQoOpAARQcSmBdFt3277d/Y/q3t7xTO2mp72PabJXMm5a2y/Yrtfbbfsn1/4bxFtnfafqPJ+27JvCazz/brtl8sndXkvWv717b32t5VOGuZ7WdsH7C93/bGglmrm6/p9NuI7Qc62XhEzOmbpD5Jb0u6RlK/pDckXVcw7xZJ6yS9Wenru0LSuubyJZL+p/DXZ0mDzeWFkl6TtKHw1/gPkp6S9GKl7+m7ki6tlPW4pL9pLvdLWlYpt0/S+5I+38X25sMe/SZJv42IdyLilKSfSPpqqbCIeFXS8VLbnyLvcETsaS5/KGm/pJUF8yIiRpt3FzZvxc6Ksj0k6cuSHi2VMVdsL1Vvx/CYJEXEqYj4Q6X4TZLejojfdbGx+VD0lZLem/T+QRUswlyyfZWktertZUvm9NneK2lY0ssRUTLv+5K+LWmiYMbZQtLPbe+2vblgztWSjkj6UXPX5FHbiwvmTXaXpKe72th8KHoKtgclbZP0QESMlMyKiE8iYo2kIUk32f5CiRzbX5E0HBG7S2z/j/hiRKyTdIekv7N9S6GcBerdzftBRKyVdFJS0ceQJMl2v6Q7Jf2sq23Oh6IfkrRq0vtDzXUXDNsL1Sv5kxHxbK3c5jDzFUm3F4q4WdKdtt9V7y7XrbZ/XCjrjIg41Pw7LGm7enf/Sjgo6eCkI6Jn1Ct+aXdI2hMRv+9qg/Oh6P8t6VrbVze/ye6S9MIcr6kztq3efbz9EfG9CnmX2V7WXB6QdJukAyWyImJLRAxFxFXq/dx+ERFfK5F1mu3Fti85fVnSlyQV+QtKRLwv6T3bq5urNknaVyLrLHerw8N2qXdoMqciYtz230v6D/UeadwaEW+VyrP9tKQ/l3Sp7YOS/jkiHiuVp95e7+uSft3cb5akf4qIfyuUd4Wkx233qfeL/KcRUeXPXpV8TtL23u9PLZD0VES8VDDvW5KebHZC70j6ZsGs07+8bpP0t51ut3koH8AFbD4cugMojKIDCVB0IAGKDiRA0YEE5lXRC5/OOGdZ5JE313nzquiSan4zq/7gyCNvLvPmW9EBFFDkhJnBwcFYsWLFjD9vdHRUg4ODna+n66xFixbN+HM++OADLV26dFZ5ExMzf2LY+eQNDw/P+HNOnTql/v7+WeXN5vs5NjamgYGBWeXN5uc+MjKiJUuWzCpvfHx8xp8z2/+fx44d0+joqM++vsgpsCtWrNCWLVtKbHpKF11U98Dk2muvrZo3NjZWNe/hhx+umrd69erpb9ShDRs2VM07ceJEtayHHnpoyus5dAcSoOhAAhQdSICiAwlQdCABig4kQNGBBCg6kECrotccmQSge9MWvXmRwUfUewna6yTdbfu60gsD0J02e/SqI5MAdK9N0dOMTAIuVJ09GGd7s+1dtneNjo5O/wkAqmlT9FYjkyLihxGxPiLW13qqKYB22hT9gh6ZBGQw7fPRa49MAtC9Vi880cwJKzUrDEBhnBkHJEDRgQQoOpAARQcSoOhAAhQdSICiAwlQdCCBIpNaapvtqJzZsj818aaojz76qGpezckikrRyZd0nQx4+fLhq3oIF9Wp2rhFr7NGBBCg6kABFBxKg6EACFB1IgKIDCVB0IAGKDiRA0YEEKDqQQJuRTFttD9t+s8aCAHSvzR79XyXdXngdAAqatugR8aqk4xXWAqAQ7qMDCTB7DUigs6Izew2Yvzh0BxJo8+e1pyX9p6TVtg/a/uvyywLQpTZDFu+usRAA5XDoDiRA0YEEKDqQAEUHEqDoQAIUHUiAogMJUHQggWJDoc41A6qE/v7+almSVPtc/q1bt1bNu/LKK6vm3XjjjVXztm/fXjVv1apV1bImJiamvJ49OpAARQcSoOhAAhQdSICiAwlQdCABig4kQNGBBCg6kABFBxJo8+KQq2y/Ynuf7bds319jYQC60+Zc93FJ/xgRe2xfImm37ZcjYl/htQHoSJvZa4cjYk9z+UNJ+yWtLL0wAN2Z0X1021dJWivptSKrAVBE66LbHpS0TdIDETEyxceZvQbMU62KbnuheiV/MiKeneo2zF4D5q82j7pb0mOS9kfE98ovCUDX2uzRb5b0dUm32t7bvP1l4XUB6FCb2Wu/lOQKawFQCGfGAQlQdCABig4kQNGBBCg6kABFBxKg6EACFB1IoMjstYULF2rlynrPZF23bl21LEnasWNH1bwnnniiat4LL7xQNW/58uVV8w4cOFA1b+PGjdWyzjWHkD06kABFBxKg6EACFB1IgKIDCVB0IAGKDiRA0YEEKDqQAEUHEmjzKrCLbO+0/UYze+27NRYGoDttznX/X0m3RsRo8/ruv7T97xHxX4XXBqAjbV4FNiSdHr2ysHmLkosC0K22k1r6bO+VNCzp5Yhg9hrwGdKq6BHxSUSskTQk6SbbXzj7NpNnr42MfGo0G4A5NKNH3SPiD5JekXT7FB87M3ttyZIlHS0PQBfaPOp+me1lzeUBSbdJqvvMfQDnpc2j7ldIetx2n3q/GH4aES+WXRaALrV51P1XktZWWAuAQjgzDkiAogMJUHQgAYoOJEDRgQQoOpAARQcSoOhAAkVmrw0MDOj6668vsekpDQ0NVcuSzj3fqpR77rmnat4NN9xQNe+RRx6pmlf753fNNddUy7r44ounvJ49OpAARQcSoOhAAhQdSICiAwlQdCABig4kQNGBBCg6kABFBxJoXfRmiMPrtnlhSOAzZiZ79Psl7S+1EADltB3JNCTpy5IeLbscACW03aN/X9K3JU2UWwqAUtpMavmKpOGI2D3N7c7MXjt+/HhnCwRw/trs0W+WdKftdyX9RNKttn989o0mz15bvnx5x8sEcD6mLXpEbImIoYi4StJdkn4REV8rvjIAneHv6EACM3opqYjYIWlHkZUAKIY9OpAARQcSoOhAAhQdSICiAwlQdCABig4kQNGBBIrMXhsfH9fRo0dLbHpKy5Ytq5YlSYODg1Xz7r333qp5R44cqZq3bdu2qnn33Xdf1TzbVfOmwh4dSICiAwlQdCABig4kQNGBBCg6kABFBxKg6EACFB1IgKIDCbQ6BbZ5qecPJX0iaTwi1pdcFIBuzeRc97+IiHonsAPoDIfuQAJtix6Sfm57t+3NJRcEoHttD92/GBGHbP+ppJdtH4iIVyffoPkFsFmSLr/88o6XCeB8tNqjR8Sh5t9hSdsl3TTFbc7MXqv9/HAAf1ybaaqLbV9y+rKkL0l6s/TCAHSnzaH75yRtb14lY4GkpyLipaKrAtCpaYseEe9I+rMKawFQCH9eAxKg6EACFB1IgKIDCVB0IAGKDiRA0YEEKDqQQJHZaydOnKg+T6umDRs2VM3btGlT1bznn3++at7ExETVvDVr1lTNO3bsWLWs8fHxKa9njw4kQNGBBCg6kABFBxKg6EACFB1IgKIDCVB0IAGKDiRA0YEEWhXd9jLbz9g+YHu/7Y2lFwagO23Pdf8XSS9FxF/Z7pf0JwXXBKBj0xbd9lJJt0j6hiRFxClJp8ouC0CX2hy6Xy3piKQf2X7d9qPNIIf/x/Zm27ts7xobG+t8oQBmr03RF0haJ+kHEbFW0klJ3zn7RpNHMg0MDHS8TADno03RD0o6GBGvNe8/o17xAXxGTFv0iHhf0nu2VzdXbZK0r+iqAHSq7aPu35L0ZPOI+zuSvlluSQC61qroEbFX0vqySwFQCmfGAQlQdCABig4kQNGBBCg6kABFBxKg6EACFB1IoMjstb6+Pi1ZsqTEpqd06NChalmS9Nxzz1XN27lzZ9W8oaGhqnkPPvhg1byPP/64at7Ro0erZTF7DUiMogMJUHQgAYoOJEDRgQQoOpAARQcSoOhAAhQdSGDaottebXvvpLcR2w9UWBuAjkx7CmxE/EbSGkmy3SfpkKTtZZcFoEszPXTfJOntiPhdicUAKGOmRb9L0tMlFgKgnNZFb17T/U5JPzvHx8/MXjt58mRX6wPQgZns0e+QtCcifj/VByfPXlu8+FMzGAHMoZkU/W5x2A58JrUqejMm+TZJz5ZdDoAS2o5kOilpReG1ACiEM+OABCg6kABFBxKg6EACFB1IgKIDCVB0IAGKDiRA0YEEHBHdb9Q+Imk2z1m/VFKtQVU1s8gjr1be5yPisrOvLFL02bK9KyLWX2hZ5JE313kcugMJUHQggflW9B9eoFnkkTenefPqPjqAMubbHh1AARQdSICiAwlQdCABig4k8H+Qb+T4cigmbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.matshow(conv_conv_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ebf49-df1a-40ab-8a25-11ddb5b07f5f",
   "metadata": {},
   "source": [
    "### 3. Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26203786-4e51-4d6b-bb0b-3dbf758df088",
   "metadata": {},
   "source": [
    "Sergey Ioffe and Christian Szegedy in their famous paper \"Batch Normalization: Accelerating Deep Network Training by\n",
    "Reducing Internal Covariate Shift\" https://arxiv.org/pdf/1502.03167.pdf suggest to perform a normalization of every batch so that the input to the next layer always has zero mean and unit variance. This shall lead to network regularization, speed up training and allow using higher learning rates. To achieve this, we need to implement BatchNorm layer that calculates means and variances of every batch for every pixel (in the direction along the batch) and then using this per-batch parameters performs normalization. \n",
    "\n",
    "Doing such a normalization, however, can make harm to the network. E.g., by supplying normalized values to sigmoid nonlinearity we will shift it into a linear regime. To fix this or \"to restore the representation power of the network\" as it is said in the paper, the authors introduce two learnable parameters gamma and beta that provide a scale and a shift to the normalized input. Let's implement batch normalization layer and check if it helps us get better results.\n",
    "\n",
    "Compared to other layers BatchNorm layer is different in the sence that it has two modes - training mode and inference mode. The difference is that in inference mode normalization is done using not per-batch statistics but per training set statistics. These statistics, namely, mean and variance, are calculated during training as a moving average with momentum that is set up as a parameter at layer initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "227a0dfc-07d5-407b-a437-bc4f4e2508b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm:\n",
    "    \"\"\" Batch normalization layer (as per https://arxiv.org/pdf/1502.03167.pdf)\n",
    "    Normalizes, i.e. achieves zero mean and standard deviation of 1 using mini-batch statistics for every pixel along the batch direction.\n",
    "    \n",
    "    Attibutes and parameters:\n",
    "    self.inference - whether the layer is in inference mode\n",
    "    self.m and self.v - mean and variance of the whole training set calculated as moving average during training\n",
    "    self.g and self.b - gamma and beta used for scaling and shifting normalized inputs. These parameters are learnable and for each mini-batch\n",
    "        a gradient step is done, see backward() method.\n",
    "    self.mu, self.var - mean and variance of a mini-batch. They have the same dimension as input image in a batch as they are calculated per-pixel\n",
    "    self.momentum - momentum used for moving average calculation\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.inference = False\n",
    "        self.g = 1\n",
    "        self.b = 1\n",
    "        self.m = 0\n",
    "        self.v = 0    \n",
    "        self.mu = None\n",
    "        self.var = None\n",
    "        self.X_ = None\n",
    "        self.X_norm_ = None\n",
    "        self.momentum = 0.1\n",
    "        \n",
    "    def forward(self, X):\n",
    "        eps = 1e-10\n",
    "        if not self.inference:\n",
    "            self.X_ = X\n",
    "            self.mu = X.mean(axis=0)\n",
    "            self.var = np.power(X - self.mu, 2).mean(axis = 0)\n",
    "            \n",
    "            self.m = (1 - self.momentum) * self.m + self.momentum * self.mu\n",
    "            self.v = (1 - self.momentum) * self.v + self.momentum * self.var\n",
    "\n",
    "            X_norm = (X - self.mu) / np.sqrt(self.var + eps)\n",
    "            self.X_norm_ = X_norm\n",
    "            return X_norm * self.g + self.b\n",
    "        \n",
    "        else:\n",
    "            return X * self.g / np.sqrt(self.v + eps) + (self.b - self.g * self.m / np.sqrt(self.v + eps))\n",
    "    \n",
    "    def backward(self, upstr_grad, lr = 0.01, debug = 0):\n",
    "        eps = 1e-10\n",
    "        dldX_norm = upstr_grad * self.g\n",
    "        \n",
    "        # remember that self.var is a matrix and self.mu is a matrix, hence dldvar and dldmu are also matrixes.\n",
    "        # the formulas for gradient calculations are provided in the original paper\n",
    "        \n",
    "        dldvar = (dldX_norm * (self.X_ - self.mu) * (-1/2) * np.power(self.var + eps, -3/2)).sum(axis=0)\n",
    "        dldmu = dldX_norm * (-1) / np.sqrt(self.var + eps).sum(axis=0) + dldvar * 1/self.X_.shape[0] * ((-2) * (self.X_ - self.mu)).sum(axis=0)\n",
    "        dldX = dldX_norm * 1 / np.sqrt(self.var + eps) + dldvar * 1 / self.X_.shape[0] * 2 * (self.X_ - self.mu) + dldmu * 1 / self.X_.shape[0]\n",
    "        dldg = (upstr_grad * self.X_norm_).sum(axis=0)\n",
    "        dldb = upstr_grad.sum(axis=0)\n",
    "        \n",
    "        self.g += (-1) * lr * dldg\n",
    "        self.b += (-1) * lr * dldb\n",
    "        return dldX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eef3d73-5004-406c-ab5f-5bbbb1357b1d",
   "metadata": {},
   "source": [
    "Let's test the new layer by inserting it into our network before every non-linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5600f9c-9f85-4193-a1e6-17b28d704fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, average_loss = 31.289167523384094\n",
      "iteration 67, average_loss = 23.70855657847177\n",
      "iteration 134, average_loss = 19.39348937425783\n",
      "iteration 201, average_loss = 17.386007861890203\n",
      "iteration 268, average_loss = 15.363376134834873\n",
      "iteration 335, average_loss = 13.624763847353439\n",
      "iteration 402, average_loss = 11.432722025324365\n",
      "iteration 469, average_loss = 11.263786274730254\n",
      "iteration 536, average_loss = 10.29598873042161\n",
      "iteration 603, average_loss = 9.096814371339397\n",
      "iteration 670, average_loss = 8.801520224185522\n",
      "iteration 737, average_loss = 8.293347728382793\n",
      "iteration 804, average_loss = 7.993773622960518\n",
      "iteration 871, average_loss = 7.193291402979352\n",
      "iteration 938, average_loss = 7.90852571555669\n",
      "iteration 1005, average_loss = 6.394621599679099\n",
      "iteration 1072, average_loss = 7.359167403050349\n",
      "iteration 1139, average_loss = 7.99861961633743\n",
      "iteration 1206, average_loss = 7.235321881971068\n",
      "iteration 1273, average_loss = 6.570723598009928\n",
      "iteration 1340, average_loss = 6.720428893661461\n",
      "iteration 1407, average_loss = 6.273359309591413\n",
      "iteration 1474, average_loss = 7.48303521909164\n",
      "iteration 1541, average_loss = 6.3805135056492785\n",
      "iteration 1608, average_loss = 5.418902200008887\n",
      "iteration 1675, average_loss = 6.516178460147546\n",
      "iteration 1742, average_loss = 5.048275703615377\n",
      "iteration 1809, average_loss = 5.391876212976997\n",
      "iteration 1876, average_loss = 6.26813762101788\n",
      "iteration 1943, average_loss = 6.4388723007857624\n"
     ]
    }
   ],
   "source": [
    "NNConv_batch = Network_multiclass([ConvLayer(pad = True), BatchNorm(), LeakyRelu(alpha=0.2), \n",
    "                          ConvLayer(pad = True), BatchNorm(), LeakyRelu(alpha=0.2), \n",
    "                          ConvLayer(pad = True), BatchNorm(), LeakyRelu(alpha=0.2), \n",
    "                          Flatten(), Linear(64, 30), BatchNorm(), LeakyRelu(alpha=0.2), Linear(30, 10), Softmax()])\n",
    "\n",
    "NNConv_batch.train_mode()\n",
    "train_network_conv(NNConv_batch, train_X, train_Y, lr = 0.003, criterion = 0.1, max_iter = 2000, debug = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d6ac2e5-6538-4cb3-95e0-07a4ae4b6aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNConv_batch.inference_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26fad82e-2586-4b46-9778-84c0eb44825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = NNConv_batch.forward(test_X)\n",
    "Y_hat = np.argmax(Y_hat, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "417879b5-a051-457d-835a-916ea4d8578a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.93, 0.9401551226551227, 0.9191233766233766)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_Y, Y_hat), precision_score(test_Y, Y_hat, average = \"macro\"), recall_score(test_Y, Y_hat, average = \"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233a7035-f3bc-465b-9979-6cc40bd64acc",
   "metadata": {},
   "source": [
    "The results look better but obviously this topic deserves more research as we need to do more tests with different learning rates, train/val split and more complex dataset with three channel inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aff35a2-0b11-4fae-9edd-c3b721bff935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
